{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODywf1gVeEx7Ekfk8gLKoE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Research-SLIIT/Financial-Risk-Analyisis-Model/blob/main/antigravity_cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtP7raRG4HEB",
        "outputId": "1a64c88a-9a28-46ef-e671-148d25d96a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "BALANCED Z-SCORE PREDICTION MODEL - HIGH ACCURACY\n",
            "Optimized for Strong Cross-Validation Performance\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# 1. IMPORTS AND SETUP\n",
        "# ============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import TimeSeriesSplit, cross_validate\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"BALANCED Z-SCORE PREDICTION MODEL - HIGH ACCURACY\")\n",
        "print(\"Optimized for Strong Cross-Validation Performance\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 2. LOAD AND PREPROCESS DATA\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"DATA LOADING & PREPROCESSING\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "file_path = '/content/Dataset.csv'  # Update path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(f\"\\n‚úì Dataset loaded: {df.shape}\")\n",
        "\n",
        "df['QuarterDate'] = pd.to_datetime(df['QuarterDate'])\n",
        "df = df.sort_values(['Company', 'QuarterDate']).reset_index(drop=True)\n",
        "\n",
        "base_features = [\n",
        "    'working_capital_to_total_assets',\n",
        "    'retained_earnings_to_total_assets',\n",
        "    'ebit_to_total_assets',\n",
        "    'mve_to_total_liabilities',\n",
        "    'sales_to_total_assets',\n",
        "    'current_ratio',\n",
        "    'debt_to_equity_ratio',\n",
        "    'net_profit_margin',\n",
        "    'z_score'\n",
        "]\n",
        "\n",
        "target_column = 'z_score_next_quarter'\n",
        "df_clean = df.dropna(subset=[target_column]).copy()\n",
        "\n",
        "# Fill missing values\n",
        "for col in base_features:\n",
        "    if df_clean[col].isnull().any():\n",
        "        df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
        "\n",
        "print(f\"‚úì Preprocessing complete: {len(df_clean)} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAKGeUuy5CKi",
        "outputId": "9f76755c-523b-49b1-fee9-ae20c6f5297f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "DATA LOADING & PREPROCESSING\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚úì Dataset loaded: (586, 12)\n",
            "‚úì Preprocessing complete: 586 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 3. BALANCED FEATURE ENGINEERING\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"BALANCED FEATURE ENGINEERING\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "df_features = df_clean.copy()\n",
        "\n",
        "# Core composite indicators\n",
        "df_features['financial_health_score'] = (\n",
        "    df_features['current_ratio'] * 0.3 +\n",
        "    df_features['z_score'] * 0.4 +\n",
        "    (1 / (df_features['debt_to_equity_ratio'] + 0.1)) * 0.3\n",
        ")\n",
        "\n",
        "df_features['profitability_composite'] = (\n",
        "    df_features['net_profit_margin'] * 0.4 +\n",
        "    df_features['ebit_to_total_assets'] * 0.3 +\n",
        "    df_features['retained_earnings_to_total_assets'] * 0.3\n",
        ")\n",
        "\n",
        "df_features['operational_efficiency'] = (\n",
        "    df_features['sales_to_total_assets'] /\n",
        "    (df_features['working_capital_to_total_assets'].abs() + 0.01)\n",
        ")\n",
        "\n",
        "df_features['leverage_risk'] = (\n",
        "    df_features['debt_to_equity_ratio'] / (df_features['current_ratio'] + 0.1)\n",
        ")\n",
        "\n",
        "# IMPORTANT: Keep z_score polynomial features (they were top performers)\n",
        "df_features['z_score_squared'] = df_features['z_score'] ** 2\n",
        "df_features['net_profit_margin_squared'] = df_features['net_profit_margin'] ** 2\n",
        "\n",
        "# Market value interactions\n",
        "df_features['mve_profitability'] = (\n",
        "    df_features['mve_to_total_liabilities'] * df_features['net_profit_margin']\n",
        ")\n",
        "\n",
        "# Time-series features\n",
        "df_features = df_features.sort_values(['Company', 'QuarterDate'])\n",
        "\n",
        "# Lag features (1, 2, 3 quarters)\n",
        "for col in ['z_score', 'net_profit_margin', 'current_ratio', 'sales_to_total_assets']:\n",
        "    df_features[f'{col}_lag1'] = df_features.groupby('Company')[col].shift(1)\n",
        "    df_features[f'{col}_lag2'] = df_features.groupby('Company')[col].shift(2)\n",
        "    df_features[f'{col}_lag3'] = df_features.groupby('Company')[col].shift(3)\n",
        "\n",
        "# Rolling statistics (3 quarters only)\n",
        "for col in ['z_score', 'net_profit_margin', 'sales_to_total_assets']:\n",
        "    df_features[f'{col}_ma3'] = (\n",
        "        df_features.groupby('Company')[col]\n",
        "        .transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
        "    )\n",
        "    df_features[f'{col}_std3'] = (\n",
        "        df_features.groupby('Company')[col]\n",
        "        .transform(lambda x: x.rolling(window=3, min_periods=1).std())\n",
        "    )\n",
        "\n",
        "# Momentum features\n",
        "for col in ['z_score', 'net_profit_margin']:\n",
        "    df_features[f'{col}_change'] = df_features.groupby('Company')[col].diff()\n",
        "    df_features[f'{col}_pct_change'] = df_features.groupby('Company')[col].pct_change()\n",
        "\n",
        "# Fill NaN values\n",
        "df_features = df_features.fillna(method='bfill').fillna(method='ffill').fillna(0)\n",
        "\n",
        "# Get all engineered features\n",
        "engineered_features = [col for col in df_features.columns\n",
        "                       if col not in ['Company', 'QuarterDate', target_column]]\n",
        "\n",
        "# Remove infinite values\n",
        "X_full = df_features[engineered_features].copy()\n",
        "X_full = X_full.replace([np.inf, -np.inf], np.nan)\n",
        "X_full = X_full.fillna(X_full.median())\n",
        "\n",
        "y_full = df_features[target_column].copy()\n",
        "\n",
        "print(f\"‚úì Created {len(engineered_features)} features\")\n",
        "print(f\"  (Base: {len(base_features)}, Engineered: {len(engineered_features) - len(base_features)})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ6OnCnV5I9S",
        "outputId": "d5aacef4-f8af-4003-f874-d20005ced445"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "BALANCED FEATURE ENGINEERING\n",
            "--------------------------------------------------------------------------------\n",
            "‚úì Created 38 features\n",
            "  (Base: 9, Engineered: 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 4. MODERATE FEATURE SELECTION (Keep 30-35 features)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"MODERATE FEATURE SELECTION (TARGET: 30-35 FEATURES)\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Calculate mutual information scores\n",
        "mi_scores = mutual_info_regression(X_full, y_full, random_state=42)\n",
        "mi_scores_df = pd.DataFrame({\n",
        "    'Feature': engineered_features,\n",
        "    'MI_Score': mi_scores\n",
        "}).sort_values('MI_Score', ascending=False)\n",
        "\n",
        "# Select top 35 features (or top 60% if dataset is smaller)\n",
        "n_features_to_keep = min(35, int(len(engineered_features) * 0.60))\n",
        "selected_features = mi_scores_df.head(n_features_to_keep)['Feature'].tolist()\n",
        "\n",
        "print(f\"‚úì Feature selection complete\")\n",
        "print(f\"  Total features: {len(engineered_features)}\")\n",
        "print(f\"  Selected features: {len(selected_features)}\")\n",
        "print(f\"  Reduction: {100*(1-len(selected_features)/len(engineered_features)):.1f}%\")\n",
        "\n",
        "print(f\"\\n  Top 15 features by importance:\")\n",
        "for idx, row in mi_scores_df.head(15).iterrows():\n",
        "    print(f\"    {list(mi_scores_df.head(15).index).index(idx)+1}. {row['Feature']}: {row['MI_Score']:.4f}\")\n",
        "\n",
        "X_selected = X_full[selected_features].copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq4g-cq-5L2s",
        "outputId": "b2afba21-1994-471a-a358-5adeacb5a721"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "MODERATE FEATURE SELECTION (TARGET: 30-35 FEATURES)\n",
            "--------------------------------------------------------------------------------\n",
            "‚úì Feature selection complete\n",
            "  Total features: 38\n",
            "  Selected features: 22\n",
            "  Reduction: 42.1%\n",
            "\n",
            "  Top 15 features by importance:\n",
            "    1. z_score: 0.7875\n",
            "    2. z_score_squared: 0.7736\n",
            "    3. z_score_ma3: 0.7324\n",
            "    4. financial_health_score: 0.6768\n",
            "    5. z_score_lag3: 0.6000\n",
            "    6. z_score_lag1: 0.5889\n",
            "    7. z_score_lag2: 0.5198\n",
            "    8. mve_to_total_liabilities: 0.4630\n",
            "    9. leverage_risk: 0.4593\n",
            "    10. current_ratio: 0.4561\n",
            "    11. working_capital_to_total_assets: 0.3963\n",
            "    12. current_ratio_lag3: 0.3895\n",
            "    13. current_ratio_lag2: 0.3852\n",
            "    14. current_ratio_lag1: 0.3839\n",
            "    15. debt_to_equity_ratio: 0.3808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 5. TIME-SERIES TRAIN/TEST SPLIT\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"TIME-SERIES TRAIN/TEST SPLIT\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "dates = df_features['QuarterDate']\n",
        "split_date = dates.quantile(0.80)\n",
        "\n",
        "train_mask = dates <= split_date\n",
        "test_mask = dates > split_date\n",
        "\n",
        "X_train = X_selected[train_mask]\n",
        "X_test = X_selected[test_mask]\n",
        "y_train = y_full[train_mask]\n",
        "y_test = y_full[test_mask]\n",
        "\n",
        "train_dates = dates[train_mask]\n",
        "test_dates = dates[test_mask]\n",
        "\n",
        "print(f\"‚úì Split based on date: {split_date.date()}\")\n",
        "print(f\"  Train: {len(X_train)} samples ({train_dates.min().date()} to {train_dates.max().date()})\")\n",
        "print(f\"  Test:  {len(X_test)} samples ({test_dates.min().date()} to {test_dates.max().date()})\")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = RobustScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"\\n‚úì Features scaled (RobustScaler)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99CMHQaS5OmX",
        "outputId": "a7fc4fbd-36e9-461e-ac1c-0ab5710d75ff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "TIME-SERIES TRAIN/TEST SPLIT\n",
            "--------------------------------------------------------------------------------\n",
            "‚úì Split based on date: 2022-09-30\n",
            "  Train: 473 samples (2012-03-31 to 2022-09-30)\n",
            "  Test:  113 samples (2022-12-31 to 2025-06-30)\n",
            "\n",
            "‚úì Features scaled (RobustScaler)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 6. BALANCED MODELS WITH MODERATE REGULARIZATION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TIME-SERIES CROSS-VALIDATION (5 FOLDS)\")\n",
        "print(\"Balanced Regularization for Optimal Performance\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# BALANCED models - moderate regularization\n",
        "cv_models = {\n",
        "    'Ridge': Ridge(alpha=1.0, random_state=42),\n",
        "    'Lasso': Lasso(alpha=0.05, random_state=42, max_iter=5000),\n",
        "    'ElasticNet': ElasticNet(alpha=0.05, l1_ratio=0.7, random_state=42, max_iter=5000),\n",
        "\n",
        "    'Random Forest': RandomForestRegressor(\n",
        "        n_estimators=300,\n",
        "        max_depth=10,  # Balanced (was 12 original, 8 over-regularized)\n",
        "        min_samples_split=12,  # Balanced\n",
        "        min_samples_leaf=6,  # Balanced\n",
        "        max_features='sqrt',\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "\n",
        "    'XGBoost': XGBRegressor(\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.05,  # Balanced (was 0.03 original, 0.02 over-regularized)\n",
        "        max_depth=5,  # Balanced\n",
        "        min_child_weight=3,  # Balanced\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        gamma=0.1,\n",
        "        reg_alpha=0.1,  # Light regularization\n",
        "        reg_lambda=0.5,  # Light regularization\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        early_stopping_rounds=50\n",
        "    ),\n",
        "\n",
        "    'LightGBM': LGBMRegressor(\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=5,\n",
        "        num_leaves=31,  # Balanced (was 25 original, 15 over-regularized)\n",
        "        min_child_samples=20,  # Balanced\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=0.5,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=-1\n",
        "    ),\n",
        "\n",
        "    'Gradient Boosting': GradientBoostingRegressor(\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=4,  # Balanced\n",
        "        min_samples_split=12,\n",
        "        min_samples_leaf=6,\n",
        "        subsample=0.8,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "cv_results = {}\n",
        "\n",
        "print(\"\\nPerforming 5-fold Time-Series Cross-Validation...\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for name, model in cv_models.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "\n",
        "    try:\n",
        "        # For XGBoost with early stopping, we need special handling\n",
        "        if name == 'XGBoost':\n",
        "            # Perform CV without early stopping for consistency\n",
        "            model_cv = XGBRegressor(\n",
        "                n_estimators=300,\n",
        "                learning_rate=0.05,\n",
        "                max_depth=5,\n",
        "                min_child_weight=3,\n",
        "                subsample=0.8,\n",
        "                colsample_bytree=0.8,\n",
        "                gamma=0.1,\n",
        "                reg_alpha=0.1,\n",
        "                reg_lambda=0.5,\n",
        "                random_state=42,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "            cv_scores = cross_validate(\n",
        "                model_cv,\n",
        "                X_train_scaled,\n",
        "                y_train,\n",
        "                cv=tscv,\n",
        "                scoring=['neg_mean_squared_error', 'r2', 'neg_mean_absolute_error'],\n",
        "                n_jobs=-1\n",
        "            )\n",
        "        else:\n",
        "            cv_scores = cross_validate(\n",
        "                model,\n",
        "                X_train_scaled,\n",
        "                y_train,\n",
        "                cv=tscv,\n",
        "                scoring=['neg_mean_squared_error', 'r2', 'neg_mean_absolute_error'],\n",
        "                n_jobs=-1\n",
        "            )\n",
        "\n",
        "        cv_scores_rmse = np.sqrt(-cv_scores['test_neg_mean_squared_error'])\n",
        "        cv_scores_r2 = cv_scores['test_r2']\n",
        "        cv_scores_mae = -cv_scores['test_neg_mean_absolute_error']\n",
        "\n",
        "        cv_results[name] = {\n",
        "            'rmse_mean': cv_scores_rmse.mean(),\n",
        "            'rmse_std': cv_scores_rmse.std(),\n",
        "            'r2_mean': cv_scores_r2.mean(),\n",
        "            'r2_std': cv_scores_r2.std(),\n",
        "            'mae_mean': cv_scores_mae.mean(),\n",
        "            'mae_std': cv_scores_mae.std(),\n",
        "            'rmse_scores': cv_scores_rmse,\n",
        "            'r2_scores': cv_scores_r2\n",
        "        }\n",
        "\n",
        "        print(f\"  RMSE: {cv_scores_rmse.mean():.4f} (¬± {cv_scores_rmse.std():.4f})\")\n",
        "        print(f\"  MAE:  {cv_scores_mae.mean():.4f} (¬± {cv_scores_mae.std():.4f})\")\n",
        "        print(f\"  R¬≤:   {cv_scores_r2.mean():.4f} (¬± {cv_scores_r2.std():.4f})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚úó Failed: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwFEc24e5SY8",
        "outputId": "b829ce17-73fa-4db7-f9a9-23336c23526a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "TIME-SERIES CROSS-VALIDATION (5 FOLDS)\n",
            "Balanced Regularization for Optimal Performance\n",
            "================================================================================\n",
            "\n",
            "Performing 5-fold Time-Series Cross-Validation...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Ridge:\n",
            "  RMSE: 0.9765 (¬± 0.3893)\n",
            "  MAE:  0.5896 (¬± 0.1665)\n",
            "  R¬≤:   -0.3104 (¬± 0.8245)\n",
            "\n",
            "Lasso:\n",
            "  RMSE: 0.8318 (¬± 0.3458)\n",
            "  MAE:  0.5380 (¬± 0.1724)\n",
            "  R¬≤:   -0.1024 (¬± 1.1991)\n",
            "\n",
            "ElasticNet:\n",
            "  RMSE: 0.8310 (¬± 0.3614)\n",
            "  MAE:  0.5221 (¬± 0.1806)\n",
            "  R¬≤:   -0.0892 (¬± 1.2038)\n",
            "\n",
            "Random Forest:\n",
            "  RMSE: 0.6673 (¬± 0.1893)\n",
            "  MAE:  0.4954 (¬± 0.1129)\n",
            "  R¬≤:   0.4901 (¬± 0.1680)\n",
            "\n",
            "XGBoost:\n",
            "  RMSE: 0.7611 (¬± 0.1677)\n",
            "  MAE:  0.5553 (¬± 0.1013)\n",
            "  R¬≤:   0.3377 (¬± 0.1671)\n",
            "\n",
            "LightGBM:\n",
            "  RMSE: 0.7831 (¬± 0.1978)\n",
            "  MAE:  0.5796 (¬± 0.1060)\n",
            "  R¬≤:   0.2666 (¬± 0.3025)\n",
            "\n",
            "Gradient Boosting:\n",
            "  RMSE: 0.7570 (¬± 0.1303)\n",
            "  MAE:  0.5496 (¬± 0.0703)\n",
            "  R¬≤:   0.3406 (¬± 0.1109)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 7. CROSS-VALIDATION SUMMARY\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"CROSS-VALIDATION SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "cv_summary = pd.DataFrame({\n",
        "    'Model': list(cv_results.keys()),\n",
        "    'CV RMSE': [f\"{cv_results[m]['rmse_mean']:.4f} ¬± {cv_results[m]['rmse_std']:.4f}\" for m in cv_results.keys()],\n",
        "    'CV MAE': [f\"{cv_results[m]['mae_mean']:.4f} ¬± {cv_results[m]['mae_std']:.4f}\" for m in cv_results.keys()],\n",
        "    'CV R¬≤': [f\"{cv_results[m]['r2_mean']:.4f} ¬± {cv_results[m]['r2_std']:.4f}\" for m in cv_results.keys()],\n",
        "    'R¬≤_mean': [cv_results[m]['r2_mean'] for m in cv_results.keys()]\n",
        "})\n",
        "\n",
        "cv_summary = cv_summary.sort_values('R¬≤_mean', ascending=False)\n",
        "print(\"\\n\" + cv_summary[['Model', 'CV RMSE', 'CV MAE', 'CV R¬≤']].to_string(index=False))\n",
        "\n",
        "print(\"\\nüí° Performance Target:\")\n",
        "print(\"  - CV R¬≤ > 0.60 = Excellent\")\n",
        "print(\"  - CV R¬≤ 0.50-0.60 = Good\")\n",
        "print(\"  - CV R¬≤ 0.40-0.50 = Acceptable\")\n",
        "print(\"  - CV R¬≤ < 0.40 = Needs improvement\")\n",
        "\n",
        "best_cv_model_name = cv_summary.iloc[0]['Model']\n",
        "print(f\"\\nüèÜ Best model by cross-validation: {best_cv_model_name}\")\n",
        "print(f\"   RMSE: {cv_results[best_cv_model_name]['rmse_mean']:.4f} (¬± {cv_results[best_cv_model_name]['rmse_std']:.4f})\")\n",
        "print(f\"   MAE:  {cv_results[best_cv_model_name]['mae_mean']:.4f} (¬± {cv_results[best_cv_model_name]['mae_std']:.4f})\")\n",
        "print(f\"   R¬≤:   {cv_results[best_cv_model_name]['r2_mean']:.4f} (¬± {cv_results[best_cv_model_name]['r2_std']:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK4yGI-d5Wr4",
        "outputId": "268044c9-a237-435c-a104-74740e5ecb05"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "CROSS-VALIDATION SUMMARY\n",
            "================================================================================\n",
            "\n",
            "            Model         CV RMSE          CV MAE            CV R¬≤\n",
            "    Random Forest 0.6673 ¬± 0.1893 0.4954 ¬± 0.1129  0.4901 ¬± 0.1680\n",
            "Gradient Boosting 0.7570 ¬± 0.1303 0.5496 ¬± 0.0703  0.3406 ¬± 0.1109\n",
            "          XGBoost 0.7611 ¬± 0.1677 0.5553 ¬± 0.1013  0.3377 ¬± 0.1671\n",
            "         LightGBM 0.7831 ¬± 0.1978 0.5796 ¬± 0.1060  0.2666 ¬± 0.3025\n",
            "       ElasticNet 0.8310 ¬± 0.3614 0.5221 ¬± 0.1806 -0.0892 ¬± 1.2038\n",
            "            Lasso 0.8318 ¬± 0.3458 0.5380 ¬± 0.1724 -0.1024 ¬± 1.1991\n",
            "            Ridge 0.9765 ¬± 0.3893 0.5896 ¬± 0.1665 -0.3104 ¬± 0.8245\n",
            "\n",
            "üí° Performance Target:\n",
            "  - CV R¬≤ > 0.60 = Excellent\n",
            "  - CV R¬≤ 0.50-0.60 = Good\n",
            "  - CV R¬≤ 0.40-0.50 = Acceptable\n",
            "  - CV R¬≤ < 0.40 = Needs improvement\n",
            "\n",
            "üèÜ Best model by cross-validation: Random Forest\n",
            "   RMSE: 0.6673 (¬± 0.1893)\n",
            "   MAE:  0.4954 (¬± 0.1129)\n",
            "   R¬≤:   0.4901 (¬± 0.1680)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 8. TRAIN FINAL MODELS AND EVALUATE\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FINAL MODEL TRAINING & TEST EVALUATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "final_results = {}\n",
        "\n",
        "for name, model in cv_models.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    try:\n",
        "        # Special handling for XGBoost with early stopping\n",
        "        if name == 'XGBoost':\n",
        "            model.fit(\n",
        "                X_train_scaled, y_train,\n",
        "                eval_set=[(X_test_scaled, y_test)],\n",
        "                verbose=False\n",
        "            )\n",
        "        else:\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        y_pred_train = model.predict(X_train_scaled)\n",
        "        y_pred_test = model.predict(X_test_scaled)\n",
        "\n",
        "        rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "        rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "        mae_test = mean_absolute_error(y_test, y_pred_test)\n",
        "        r2_test = r2_score(y_test, y_pred_test)\n",
        "\n",
        "        overfit_ratio = rmse_test / rmse_train\n",
        "\n",
        "        final_results[name] = {\n",
        "            'model': model,\n",
        "            'predictions': y_pred_test,\n",
        "            'rmse_train': rmse_train,\n",
        "            'rmse_test': rmse_test,\n",
        "            'mae': mae_test,\n",
        "            'r2': r2_test,\n",
        "            'overfit_ratio': overfit_ratio\n",
        "        }\n",
        "\n",
        "        print(f\"  Train RMSE: {rmse_train:.4f}\")\n",
        "        print(f\"  Test RMSE:  {rmse_test:.4f}\")\n",
        "        print(f\"  Test MAE:   {mae_test:.4f}\")\n",
        "        print(f\"  Test R¬≤:    {r2_test:.4f}\")\n",
        "        print(f\"  Overfit Ratio: {overfit_ratio:.2f}x {'‚úì' if overfit_ratio < 1.5 else '‚ö†'}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚úó Failed: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYOorPde5ZC8",
        "outputId": "81e63bc9-6cfa-49dc-f8c9-a073ce724089"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL MODEL TRAINING & TEST EVALUATION\n",
            "================================================================================\n",
            "\n",
            "Ridge:\n",
            "----------------------------------------\n",
            "  Train RMSE: 0.5447\n",
            "  Test RMSE:  0.5225\n",
            "  Test MAE:   0.3814\n",
            "  Test R¬≤:    0.7958\n",
            "  Overfit Ratio: 0.96x ‚úì\n",
            "\n",
            "Lasso:\n",
            "----------------------------------------\n",
            "  Train RMSE: 0.5760\n",
            "  Test RMSE:  0.6146\n",
            "  Test MAE:   0.4499\n",
            "  Test R¬≤:    0.7174\n",
            "  Overfit Ratio: 1.07x ‚úì\n",
            "\n",
            "ElasticNet:\n",
            "----------------------------------------\n",
            "  Train RMSE: 0.5711\n",
            "  Test RMSE:  0.5931\n",
            "  Test MAE:   0.4322\n",
            "  Test R¬≤:    0.7369\n",
            "  Overfit Ratio: 1.04x ‚úì\n",
            "\n",
            "Random Forest:\n",
            "----------------------------------------\n",
            "  Train RMSE: 0.4324\n",
            "  Test RMSE:  0.4851\n",
            "  Test MAE:   0.3639\n",
            "  Test R¬≤:    0.8239\n",
            "  Overfit Ratio: 1.12x ‚úì\n",
            "\n",
            "XGBoost:\n",
            "----------------------------------------\n",
            "  Train RMSE: 0.2821\n",
            "  Test RMSE:  0.4870\n",
            "  Test MAE:   0.3497\n",
            "  Test R¬≤:    0.8226\n",
            "  Overfit Ratio: 1.73x ‚ö†\n",
            "\n",
            "LightGBM:\n",
            "----------------------------------------\n",
            "  Train RMSE: 0.2209\n",
            "  Test RMSE:  0.5253\n",
            "  Test MAE:   0.4045\n",
            "  Test R¬≤:    0.7936\n",
            "  Overfit Ratio: 2.38x ‚ö†\n",
            "\n",
            "Gradient Boosting:\n",
            "----------------------------------------\n",
            "  Train RMSE: 0.1431\n",
            "  Test RMSE:  0.4865\n",
            "  Test MAE:   0.3805\n",
            "  Test R¬≤:    0.8229\n",
            "  Overfit Ratio: 3.40x ‚ö†\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 9. COMPREHENSIVE COMPARISON\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"COMPREHENSIVE MODEL COMPARISON\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': list(final_results.keys()),\n",
        "    'CV R¬≤': [cv_results[m]['r2_mean'] for m in final_results.keys()],\n",
        "    'CV RMSE': [cv_results[m]['rmse_mean'] for m in final_results.keys()],\n",
        "    'Test R¬≤': [final_results[m]['r2'] for m in final_results.keys()],\n",
        "    'Test RMSE': [final_results[m]['rmse_test'] for m in final_results.keys()],\n",
        "    'Overfit': [final_results[m]['overfit_ratio'] for m in final_results.keys()]\n",
        "})\n",
        "\n",
        "comparison_df = comparison_df.sort_values('CV R¬≤', ascending=False)\n",
        "print(\"\\n\" + comparison_df.to_string(index=False))\n",
        "\n",
        "print(\"\\nüìä What to Look For:\")\n",
        "print(\"  ‚Ä¢ High CV R¬≤ (>0.60 is excellent)\")\n",
        "print(\"  ‚Ä¢ Low Overfit Ratio (<1.5x is good)\")\n",
        "print(\"  ‚Ä¢ CV R¬≤ close to Test R¬≤ (indicates reliability)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLqYiDrz5eWk",
        "outputId": "477db336-74da-43c6-f35b-564f7d26968c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "COMPREHENSIVE MODEL COMPARISON\n",
            "================================================================================\n",
            "\n",
            "            Model     CV R¬≤  CV RMSE  Test R¬≤  Test RMSE  Overfit\n",
            "    Random Forest  0.490064 0.667270 0.823943   0.485145 1.121950\n",
            "Gradient Boosting  0.340601 0.756993 0.822929   0.486540 3.399543\n",
            "          XGBoost  0.337721 0.761052 0.822624   0.486959 1.726240\n",
            "         LightGBM  0.266635 0.783052 0.793613   0.525275 2.377614\n",
            "       ElasticNet -0.089202 0.830986 0.736865   0.593109 1.038510\n",
            "            Lasso -0.102401 0.831789 0.717441   0.614609 1.067074\n",
            "            Ridge -0.310411 0.976525 0.795821   0.522456 0.959102\n",
            "\n",
            "üìä What to Look For:\n",
            "  ‚Ä¢ High CV R¬≤ (>0.60 is excellent)\n",
            "  ‚Ä¢ Low Overfit Ratio (<1.5x is good)\n",
            "  ‚Ä¢ CV R¬≤ close to Test R¬≤ (indicates reliability)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 10. SELECT BEST MODEL\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"BEST MODEL SELECTION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "best_model_name = comparison_df.iloc[0]['Model']\n",
        "best_model = final_results[best_model_name]['model']\n",
        "best_metrics = final_results[best_model_name]\n",
        "\n",
        "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
        "print(f\"\\n  Cross-Validation Performance (Most Reliable):\")\n",
        "print(f\"    RMSE: {cv_results[best_model_name]['rmse_mean']:.4f} (¬± {cv_results[best_model_name]['rmse_std']:.4f})\")\n",
        "print(f\"    R¬≤:   {cv_results[best_model_name]['r2_mean']:.4f} (¬± {cv_results[best_model_name]['r2_std']:.4f})\")\n",
        "print(f\"\\n  Test Set Performance:\")\n",
        "print(f\"    RMSE: {best_metrics['rmse_test']:.4f}\")\n",
        "print(f\"    R¬≤:   {best_metrics['r2']:.4f}\")\n",
        "print(f\"\\n  Generalization:\")\n",
        "print(f\"    Overfit Ratio: {best_metrics['overfit_ratio']:.2f}x\")\n",
        "print(f\"    Status: {'‚úì Excellent' if best_metrics['overfit_ratio'] < 1.3 else '‚úì Good' if best_metrics['overfit_ratio'] < 1.5 else '‚ö† Acceptable'}\")\n",
        "\n",
        "# Performance assessment\n",
        "cv_r2 = cv_results[best_model_name]['r2_mean']\n",
        "if cv_r2 >= 0.60:\n",
        "    assessment = \"üéâ EXCELLENT - Production Ready!\"\n",
        "elif cv_r2 >= 0.50:\n",
        "    assessment = \"‚úÖ GOOD - Reliable Performance\"\n",
        "elif cv_r2 >= 0.40:\n",
        "    assessment = \"üëç ACCEPTABLE - Usable\"\n",
        "else:\n",
        "    assessment = \"‚ö†Ô∏è NEEDS IMPROVEMENT\"\n",
        "\n",
        "print(f\"\\n  Overall Assessment: {assessment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6V1cTi55gk9",
        "outputId": "961e5949-6b59-45da-ccf0-c4f34c70e304"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "BEST MODEL SELECTION\n",
            "================================================================================\n",
            "\n",
            "üèÜ BEST MODEL: Random Forest\n",
            "\n",
            "  Cross-Validation Performance (Most Reliable):\n",
            "    RMSE: 0.6673 (¬± 0.1893)\n",
            "    R¬≤:   0.4901 (¬± 0.1680)\n",
            "\n",
            "  Test Set Performance:\n",
            "    RMSE: 0.4851\n",
            "    R¬≤:   0.8239\n",
            "\n",
            "  Generalization:\n",
            "    Overfit Ratio: 1.12x\n",
            "    Status: ‚úì Excellent\n",
            "\n",
            "  Overall Assessment: üëç ACCEPTABLE - Usable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 11. FEATURE IMPORTANCE\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': selected_features,\n",
        "        'Importance': best_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    print(f\"\\nTop 15 Most Important Features:\")\n",
        "    for idx, row in feature_importance.head(15).iterrows():\n",
        "        print(f\"  {list(feature_importance.head(15).index).index(idx)+1}. {row['Feature']}: {row['Importance']:.4f}\")\n",
        "\n",
        "elif hasattr(best_model, 'coef_'):\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': selected_features,\n",
        "        'Coefficient': np.abs(best_model.coef_)\n",
        "    }).sort_values('Coefficient', ascending=False)\n",
        "\n",
        "    print(f\"\\nTop 15 Most Important Features:\")\n",
        "    for idx, row in feature_importance.head(15).iterrows():\n",
        "        print(f\"  {list(feature_importance.head(15).index).index(idx)+1}. {row['Feature']}: {row['Coefficient']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s58ilYYW5imG",
        "outputId": "537b00d1-345d-4e08-c46a-8965a95d707f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FEATURE IMPORTANCE ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "Top 15 Most Important Features:\n",
            "  1. z_score_ma3: 0.1461\n",
            "  2. z_score_squared: 0.1368\n",
            "  3. financial_health_score: 0.1284\n",
            "  4. z_score: 0.1133\n",
            "  5. z_score_lag1: 0.0748\n",
            "  6. leverage_risk: 0.0647\n",
            "  7. mve_to_total_liabilities: 0.0641\n",
            "  8. z_score_lag3: 0.0464\n",
            "  9. debt_to_equity_ratio: 0.0391\n",
            "  10. z_score_lag2: 0.0285\n",
            "  11. current_ratio: 0.0262\n",
            "  12. current_ratio_lag1: 0.0207\n",
            "  13. working_capital_to_total_assets: 0.0180\n",
            "  14. retained_earnings_to_total_assets: 0.0157\n",
            "  15. mve_profitability: 0.0141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 12. SAMPLE PREDICTIONS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"SAMPLE PREDICTIONS (First 15 Test Samples)\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "sample_predictions = pd.DataFrame({\n",
        "    'Date': test_dates.iloc[:15].dt.date.values,\n",
        "    'Actual': y_test.iloc[:15].values,\n",
        "    'Predicted': best_metrics['predictions'][:15],\n",
        "    'Error': np.abs(y_test.iloc[:15].values - best_metrics['predictions'][:15]),\n",
        "    'Error %': (np.abs(y_test.iloc[:15].values - best_metrics['predictions'][:15]) /\n",
        "                (np.abs(y_test.iloc[:15].values) + 0.01) * 100)\n",
        "})\n",
        "\n",
        "print(\"\\n\" + sample_predictions.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wycnzPve5kK_",
        "outputId": "1becc9d4-5724-4d6f-c784-d4a13aea7df3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "SAMPLE PREDICTIONS (First 15 Test Samples)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "      Date  Actual  Predicted    Error   Error %\n",
            "2022-12-31  3.0259   2.722562 0.303338  9.991694\n",
            "2023-03-31  2.2309   2.763997 0.533097 23.789411\n",
            "2023-06-30  2.7241   2.773322 0.049222  1.800282\n",
            "2023-09-30  2.5707   2.605913 0.035213  1.364458\n",
            "2023-12-31  3.7305   2.867174 0.863326 23.080485\n",
            "2024-03-31  2.8571   2.689575 0.167525  5.843016\n",
            "2024-06-30  3.4050   2.982742 0.422258 12.364815\n",
            "2024-09-30  3.9435   2.880839 1.062661 26.878990\n",
            "2024-12-31  4.0525   3.153242 0.899258 22.135584\n",
            "2025-03-31  3.6826   3.055046 0.627554 16.994920\n",
            "2025-06-30  2.6996   3.212835 0.513235 18.941370\n",
            "2022-12-31  1.1719   1.133767 0.038133  3.226375\n",
            "2023-03-31  1.2750   1.109399 0.165601 12.887267\n",
            "2023-06-30  0.8961   1.173057 0.276957 30.565821\n",
            "2023-09-30  0.8480   1.037951 0.189951 22.138793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 13. FINAL SUMMARY\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FINAL RECOMMENDATIONS & INSIGHTS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\n‚úÖ RECOMMENDED MODEL: {best_model_name}\")\n",
        "print(f\"\\nüìä Expected Performance on New Data:\")\n",
        "print(f\"   ‚Ä¢ RMSE: {cv_results[best_model_name]['rmse_mean']:.4f} ¬± {cv_results[best_model_name]['rmse_std']:.4f}\")\n",
        "print(f\"   ‚Ä¢ R¬≤:   {cv_results[best_model_name]['r2_mean']:.4f} ¬± {cv_results[best_model_name]['r2_std']:.4f}\")\n",
        "print(f\"\\nüí° Key Insights:\")\n",
        "print(f\"   ‚Ä¢ Features used: {len(selected_features)} (balanced complexity)\")\n",
        "print(f\"   ‚Ä¢ Overfitting risk: {'Low' if best_metrics['overfit_ratio'] < 1.5 else 'Moderate'}\")\n",
        "print(f\"   ‚Ä¢ Model stability: {'High' if cv_results[best_model_name]['r2_std'] < 0.20 else 'Moderate'}\")\n",
        "print(f\"\\n‚ö° Improvements vs Original:\")\n",
        "print(f\"   ‚Ä¢ Original CV R¬≤: ~0.43 (Random Forest)\")\n",
        "print(f\"   ‚Ä¢ Current CV R¬≤:  {cv_results[best_model_name]['r2_mean']:.4f}\")\n",
        "print(f\"   ‚Ä¢ Improvement: {((cv_results[best_model_name]['r2_mean'] - 0.43) / 0.43 * 100):.1f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"MODEL OPTIMIZATION COMPLETE ‚úì\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OciWFg8G5muP",
        "outputId": "065273ec-0d6c-432b-ae62-39e12a231146"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL RECOMMENDATIONS & INSIGHTS\n",
            "================================================================================\n",
            "\n",
            "‚úÖ RECOMMENDED MODEL: Random Forest\n",
            "\n",
            "üìä Expected Performance on New Data:\n",
            "   ‚Ä¢ RMSE: 0.6673 ¬± 0.1893\n",
            "   ‚Ä¢ R¬≤:   0.4901 ¬± 0.1680\n",
            "\n",
            "üí° Key Insights:\n",
            "   ‚Ä¢ Features used: 22 (balanced complexity)\n",
            "   ‚Ä¢ Overfitting risk: Low\n",
            "   ‚Ä¢ Model stability: High\n",
            "\n",
            "‚ö° Improvements vs Original:\n",
            "   ‚Ä¢ Original CV R¬≤: ~0.43 (Random Forest)\n",
            "   ‚Ä¢ Current CV R¬≤:  0.4901\n",
            "   ‚Ä¢ Improvement: 14.0%\n",
            "\n",
            "================================================================================\n",
            "MODEL OPTIMIZATION COMPLETE ‚úì\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}